{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958dee87-2745-4095-b4cb-d971fbb1b1b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shotsData not found. The page structure may have changed, or the match_id is invalid/private.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    101\u001b[39m match_id = \u001b[32m28780\u001b[39m  \u001b[38;5;66;03m# <-- CHANGE THIS (example ID). Use an Understat match ID.\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Fetch shots and save to CSV\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m shots = fetch_understat_match_shots(match_id)\n\u001b[32m    105\u001b[39m df = shots_to_dataframe(shots)\n\u001b[32m    107\u001b[39m csv_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmatch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatch_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_xg_events.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mfetch_understat_match_shots\u001b[39m\u001b[34m(match_id)\u001b[39m\n\u001b[32m     60\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shots_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mshotsData not found. The page structure may have changed, or the match_id is invalid/private.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# shots_data should be dict with 'h' (home) and 'a' (away)\u001b[39;00m\n\u001b[32m     66\u001b[39m all_shots = []\n",
      "\u001b[31mRuntimeError\u001b[39m: shotsData not found. The page structure may have changed, or the match_id is invalid/private."
     ]
    }
   ],
   "source": [
    "# Premier League â€“ Export xG Events for One Match (Understat)\n",
    "# NOTE:\n",
    "# 1) Change `match_id` below.\n",
    "# 2) Run all cells. A CSV named `match_<match_id>_xg_events.csv` will be saved.\n",
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def _extract_shots_json_from_script(script_text: str):\n",
    "    \"\"\"\n",
    "    Robustly extract the JSON for shotsData from an Understat match page <script>.\n",
    "    Handles both:\n",
    "      - shotsData = JSON.parse('...');   (escaped JSON string)\n",
    "      - shotsData = {...};               (direct JSON object)\n",
    "    Returns a Python dict with keys like 'h' and 'a'.\n",
    "    \"\"\"\n",
    "    text = script_text or \"\"\n",
    "    # 1) Try JSON.parse('...') pattern (allow newlines)\n",
    "    m = re.search(r\"shotsData\\s*=\\s*JSON\\.parse\\((?P<q>['\\\"])(?P<data>.*?)(?P=q)\\)\\s*;\", text, re.DOTALL)\n",
    "    if m:\n",
    "        escaped = m.group(\"data\")\n",
    "        # The captured data is a JS string literal containing JSON; we must unescape JS-style escapes.\n",
    "        # Using 'unicode_escape' handles sequences like \\n, \\t, \\uXXXX, \\xNN.\n",
    "        unescaped = bytes(escaped, \"utf-8\").decode(\"unicode_escape\")\n",
    "        return json.loads(unescaped)\n",
    "\n",
    "    # 2) Fallback: direct assignment shotsData = {...};\n",
    "    m2 = re.search(r\"shotsData\\s*=\\s*(\\{.*?\\})\\s*;\", text, re.DOTALL)\n",
    "    if m2:\n",
    "        return json.loads(m2.group(1))\n",
    "\n",
    "    raise RuntimeError(\"Could not extract shotsData JSON from script block.\")\n",
    "\n",
    "def fetch_understat_match_shots(match_id: int):\n",
    "    \"\"\"\n",
    "    Fetch shots (with xG) for a single match from Understat.\n",
    "    Returns a list of shot dicts with 'team_side' added (home/away).\n",
    "    \"\"\"\n",
    "    url = f\"https://understat.com/match/{match_id}\"\n",
    "    resp = requests.get(url, headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    shots_data = None\n",
    "\n",
    "    # Search all scripts for one that contains 'shotsData'\n",
    "    for s in soup.find_all(\"script\"):\n",
    "        txt = s.get_text() or \"\"\n",
    "        if \"shotsData\" in txt:\n",
    "            try:\n",
    "                shots_data = _extract_shots_json_from_script(txt)\n",
    "                break\n",
    "            except Exception:\n",
    "                # Try next script if this one didn't parse cleanly\n",
    "                continue\n",
    "\n",
    "    if shots_data is None:\n",
    "        raise RuntimeError(\"shotsData not found. The page structure may have changed, or the match_id is invalid/private.\")\n",
    "\n",
    "    # shots_data should be dict with 'h' (home) and 'a' (away)\n",
    "    all_shots = []\n",
    "    for side_key, side_label in ((\"h\", \"home\"), (\"a\", \"away\")):\n",
    "        for shot in shots_data.get(side_key, []):\n",
    "            item = dict(shot)\n",
    "            item[\"team_side\"] = side_label\n",
    "            all_shots.append(item)\n",
    "    return all_shots\n",
    "\n",
    "def shots_to_dataframe(shots):\n",
    "    \"\"\"Convert Understat shots list into a clean DataFrame with common fields.\"\"\"\n",
    "    records = []\n",
    "    for s in shots:\n",
    "        records.append({\n",
    "            \"match_id\": s.get(\"match_id\"),\n",
    "            \"shot_id\": s.get(\"id\"),\n",
    "            \"team\": s.get(\"team\") or s.get(\"h_team\") or s.get(\"a_team\"),\n",
    "            \"team_side\": s.get(\"team_side\"),\n",
    "            \"player\": s.get(\"player\"),\n",
    "            \"minute\": s.get(\"minute\"),\n",
    "            \"second\": s.get(\"second\"),\n",
    "            \"result\": s.get(\"result\"),\n",
    "            \"situation\": s.get(\"situation\"),\n",
    "            \"shotType\": s.get(\"shotType\"),\n",
    "            \"x\": s.get(\"x\") or s.get(\"X\"),\n",
    "            \"y\": s.get(\"y\") or s.get(\"Y\"),\n",
    "            \"xG\": float(s.get(\"xG\")) if s.get(\"xG\") not in (None, \"\") else None,\n",
    "            \"player_assisted\": s.get(\"player_assisted\"),\n",
    "            \"lastAction\": s.get(\"lastAction\"),\n",
    "        })\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values(by=[\"minute\", \"second\", \"team_side\", \"player\"], na_position=\"last\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# ðŸ”¢ Enter your match ID here\n",
    "match_id = 28780  # <-- CHANGE THIS (example ID). Use an Understat match ID.\n",
    "\n",
    "# Fetch shots and save to CSV\n",
    "shots = fetch_understat_match_shots(match_id)\n",
    "df = shots_to_dataframe(shots)\n",
    "\n",
    "csv_path = f\"match_{match_id}_xg_events.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved {len(df)} xG/shot events to: {csv_path}\")\n",
    "\n",
    "# Show first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b1864f-7b2a-4712-b63b-d9e462b868b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 7-8: truncated \\xXX escape (3129987837.py, line 41)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"Decode \\xNN / \\uXXXX style escapes from JSON.parse('...') payloads.\"\"\"\u001b[39m\n                                                                             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 7-8: truncated \\xXX escape\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# NOTE (read me):\n",
    "# This script prints every EPL match ID (with the fixture text)\n",
    "# in a given date window of the 2025/26 season, AND for each ID\n",
    "# saves a CSV of all xG chances (shots) in that match.\n",
    "#\n",
    "# âœ… What you edit:\n",
    "#   - Change START_DATE and END_DATE (YYYY-MM-DD).\n",
    "#   - Optionally change LEAGUE and SEASON.\n",
    "#   - Optionally change OUT_DIR (where the per-match CSVs go).\n",
    "#\n",
    "# Output:\n",
    "#   - Console: lines like  ID 28778 â€” Liverpool v Bournemouth (2025-08-15 19:00)\n",
    "#   - Files:   <OUT_DIR>/match_28778_shots.csv  (one file per match)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# ======== EDIT THESE ========\n",
    "LEAGUE = \"EPL\"\n",
    "SEASON = 2025           # Understat \"2025\" = 2025/26 season\n",
    "START_DATE = \"2025-08-15\"\n",
    "END_DATE   = \"2025-08-18\"\n",
    "OUT_DIR    = \"data/understat/shots\"   # folder to save per-match CSVs\n",
    "# ============================\n",
    "\n",
    "BASE = \"https://understat.com\"\n",
    "S = requests.Session()\n",
    "S.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.google.com/\",\n",
    "})\n",
    "\n",
    "# ---------- small helpers ----------\n",
    "def _decode_js_escaped(s: str) -> str:\n",
    "    \"\"\"Decode \\xNN / \\uXXXX style escapes from JSON.parse('...') payloads.\"\"\"\n",
    "    return bytes(s, \"utf-8\").decode(\"unicode_escape\")\n",
    "\n",
    "def _extract_array(text: str) -> str:\n",
    "    \"\"\"Quote/escape-aware bracket scan that returns the JSON array substring.\"\"\"\n",
    "    i = text.find(\"[\")\n",
    "    if i == -1:\n",
    "        raise RuntimeError(\"No '[' found in decoded datesData.\")\n",
    "    out, depth, esc, in_str, quote = [], 0, False, False, \"\"\n",
    "    j = i\n",
    "    while j < len(text):\n",
    "        ch = text[j]\n",
    "        out.append(ch)\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            elif ch == \"\\\\\":\n",
    "                esc = True\n",
    "            elif ch == quote:\n",
    "                in_str = False\n",
    "        else:\n",
    "            if ch in ('\"', \"'\"):\n",
    "                in_str = True; quote = ch\n",
    "            elif ch == \"[\":\n",
    "                depth += 1\n",
    "            elif ch == \"]\":\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    break\n",
    "        j += 1\n",
    "    if depth != 0:\n",
    "        raise RuntimeError(\"Unbalanced brackets while slicing datesData.\")\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _fetch_week_fixtures(league: str, season: int, week: int) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame of fixtures for a given week (or empty DF if none).\"\"\"\n",
    "    url = f\"{BASE}/league/{league}/{season}?week={week}\"\n",
    "    html = S.get(url, timeout=30)\n",
    "    html.raise_for_status()\n",
    "    text = html.text\n",
    "\n",
    "    # A) datesData = JSON.parse(' ... ');\n",
    "    m = re.search(r\"datesData\\s*=\\s*JSON\\.parse\\('(.*?)'\\);\", text, flags=re.S)\n",
    "    if m:\n",
    "        decoded = _decode_js_escaped(m.group(1))\n",
    "        arr_txt = _extract_array(decoded)\n",
    "        data = json.loads(arr_txt)\n",
    "    else:\n",
    "        # B) Fallback: datesData = [ ... ];\n",
    "        m2 = re.search(r\"datesData\\s*=\\s*(\\[[\\s\\S]*?\\]);\", text, flags=re.S)\n",
    "        if not m2:\n",
    "            return pd.DataFrame()  # week page without fixtures\n",
    "        data = json.loads(m2.group(1))\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # kickoff datetime (make tz-naive)\n",
    "    for col in (\"datetime\", \"date\", \"time\"):\n",
    "        if col in df.columns:\n",
    "            df[\"kickoff\"] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            break\n",
    "    else:\n",
    "        df[\"kickoff\"] = pd.NaT\n",
    "    df[\"kickoff\"] = df[\"kickoff\"].dt.tz_localize(None)\n",
    "\n",
    "    # Normalize a few common fields\n",
    "    if \"id\" in df.columns:\n",
    "        df[\"match_id\"] = df[\"id\"].astype(\"Int64\")\n",
    "    if \"h.title\" in df.columns:\n",
    "        df.rename(columns={\"h.title\": \"home_team\", \"a.title\": \"away_team\"}, inplace=True)\n",
    "\n",
    "    return df[[\"match_id\", \"home_team\", \"away_team\", \"kickoff\"]].copy()\n",
    "\n",
    "def _collect_fixtures_in_window(league: str, season: int, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Scan a handful of weeks and return fixtures filtered+deduped by match_id.\"\"\"\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end_excl = pd.to_datetime(end_date) + pd.Timedelta(days=1)  # inclusive end\n",
    "    all_rows = []\n",
    "\n",
    "    for week in range(1, 6):  # early season window typically within first few weeks\n",
    "        df = _fetch_week_fixtures(league, season, week)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        all_rows.append(df)\n",
    "        wk_min = df[\"kickoff\"].min()\n",
    "        if pd.notna(wk_min) and wk_min > end_excl + pd.Timedelta(days=7):\n",
    "            break\n",
    "\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame(columns=[\"match_id\", \"home_team\", \"away_team\", \"kickoff\"])\n",
    "\n",
    "    fixtures = pd.concat(all_rows, ignore_index=True)\n",
    "    in_window = fixtures[(fixtures[\"kickoff\"] >= start) & (fixtures[\"kickoff\"] < end_excl)]\n",
    "    in_window = in_window.drop_duplicates(subset=[\"match_id\"]).sort_values(\"kickoff\").reset_index(drop=True)\n",
    "    return in_window\n",
    "\n",
    "# ---------- robust shots extractor ----------\n",
    "def _find_in_obj(obj, key=\"shotsData\"):\n",
    "    \"\"\"Recursively search dict/list for a key; return value or None.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        if key in obj:\n",
    "            return obj[key]\n",
    "        for v in obj.values():\n",
    "            found = _find_in_obj(v, key)\n",
    "            if found is not None:\n",
    "                return found\n",
    "    elif isinstance(obj, list):\n",
    "        for it in obj:\n",
    "            found = _find_in_obj(it, key)\n",
    "            if found is not None:\n",
    "                return found\n",
    "    return None\n",
    "\n",
    "def _fetch_match_shots(match_id: int) -> pd.DataFrame:\n",
    "    \"\"\"Fetch shots (xG events) for a single match_id and return a DataFrame.\"\"\"\n",
    "    url = f\"{BASE}/match/{match_id}\"\n",
    "    html = S.get(url, timeout=30)\n",
    "    html.raise_for_status()\n",
    "    text = html.text\n",
    "\n",
    "    shots = None\n",
    "\n",
    "    # A) shotsData = JSON.parse(' ... ');\n",
    "    m = re.search(r\"shotsData\\s*=\\s*JSON\\.parse\\('(.*?)'\\);\", text, flags=re.S)\n",
    "    if m:\n",
    "        decoded = _decode_js_escaped(m.group(1))\n",
    "        # For shotsData the root is an object: {\"h\":[...], \"a\":[...]}\n",
    "        # Safely slice the JSON object:\n",
    "        # find first { and its matching }\n",
    "        t = decoded\n",
    "        i = t.find(\"{\")\n",
    "        if i == -1:\n",
    "            raise RuntimeError(\"Couldn't find '{' in shotsData payload.\")\n",
    "        out, depth, esc, in_str, quote = [], 0, False, False, \"\"\n",
    "        j = i\n",
    "        while j < len(t):\n",
    "            ch = t[j]\n",
    "            out.append(ch)\n",
    "            if in_str:\n",
    "                if esc:\n",
    "                    esc = False\n",
    "                elif ch == \"\\\\\":\n",
    "                    esc = True\n",
    "                elif ch == quote:\n",
    "                    in_str = False\n",
    "            else:\n",
    "                if ch in ('\"', \"'\"):\n",
    "                    in_str = True; quote = ch\n",
    "                elif ch == \"{\":\n",
    "                    depth += 1\n",
    "                elif ch == \"}\":\n",
    "                    depth -= 1\n",
    "                    if depth == 0:\n",
    "                        break\n",
    "            j += 1\n",
    "        obj_txt = \"\".join(out)\n",
    "        shots = json.loads(obj_txt)\n",
    "\n",
    "    # B) window.__NUXT__ = {...}; recurse to 'shotsData'\n",
    "    if shots is None:\n",
    "        m2 = re.search(r\"window\\.__NUXT__\\s*=\\s*({[\\s\\S]*?});\", text, flags=re.S)\n",
    "        if m2:\n",
    "            try:\n",
    "                nuxt = json.loads(m2.group(1))\n",
    "                shots = _find_in_obj(nuxt, key=\"shotsData\")\n",
    "            except Exception:\n",
    "                shots = None\n",
    "\n",
    "    # C) Fallback: shotsData = {...};\n",
    "    if shots is None:\n",
    "        m3 = re.search(r\"shotsData\\s*=\\s*({[\\s\\S]*?});\", text, flags=re.S)\n",
    "        if m3:\n",
    "            shots = json.loads(m3.group(1))\n",
    "\n",
    "    if shots is None:\n",
    "        raise RuntimeError(f\"Could not extract shots for match {match_id}\")\n",
    "\n",
    "    # Normalize into rows\n",
    "    rows = []\n",
    "    for side in (\"h\", \"a\"):\n",
    "        for ev in shots.get(side, []):\n",
    "            rows.append({\n",
    "                \"match_id\": match_id,\n",
    "                \"side\": side,\n",
    "                \"team\": ev.get(\"team\"),\n",
    "                \"player\": ev.get(\"player\"),\n",
    "                \"player_id\": ev.get(\"player_id\"),\n",
    "                \"minute\": int(ev.get(\"minute\", 0)) if ev.get(\"minute\") is not None else None,\n",
    "                \"second\": int(ev.get(\"second\", 0)) if ev.get(\"second\") is not None else None,\n",
    "                \"xG\": float(ev.get(\"xG\", 0.0)) if ev.get(\"xG\") is not None else None,\n",
    "                \"result\": ev.get(\"result\"),\n",
    "                \"situation\": ev.get(\"situation\"),\n",
    "                \"shotType\": ev.get(\"shotType\"),\n",
    "                \"X\": float(ev.get(\"X\")) if ev.get(\"X\") is not None else None,\n",
    "                \"Y\": float(ev.get(\"Y\")) if ev.get(\"Y\") is not None else None,\n",
    "                \"assist\": ev.get(\"assist\"),\n",
    "                \"assist_id\": ev.get(\"assist_id\"),\n",
    "                \"h_a\": ev.get(\"h_a\"),\n",
    "                \"lastAction\": ev.get(\"lastAction\"),\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"minute\", \"second\"], na_position=\"last\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _ensure_dir(p: str):\n",
    "    if p and not os.path.isdir(p):\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    _ensure_dir(OUT_DIR)\n",
    "\n",
    "    win = _collect_fixtures_in_window(LEAGUE, SEASON, START_DATE, END_DATE)\n",
    "    if win.empty:\n",
    "        print(f\"No fixtures found between {START_DATE} and {END_DATE}.\")\n",
    "        return\n",
    "\n",
    "    for _, r in win.iterrows():\n",
    "        mid  = int(r[\"match_id\"])\n",
    "        home = r.get(\"home_team\", \"\")\n",
    "        away = r.get(\"away_team\", \"\")\n",
    "        ko   = r[\"kickoff\"].strftime(\"%Y-%m-%d %H:%M\")\n",
    "        print(f\"ID {mid} â€” {home} v {away} ({ko})\")\n",
    "\n",
    "        # Fetch shots and save CSV per match\n",
    "        try:\n",
    "            shots_df = _fetch_match_shots(mid)\n",
    "            out_path = os.path.join(OUT_DIR, f\"match_{mid}_shots.csv\")\n",
    "            shots_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "        except Exception as e:\n",
    "            print(f\"  â–³ Could not save shots for {mid}: {e}\")\n",
    "        else:\n",
    "            print(f\"  âœ“ Saved {len(shots_df)} shots -> {out_path}\")\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46026d8c-4252-4db1-b2e1-ef05137fd890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pl311]",
   "language": "python",
   "name": "conda-env-pl311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
