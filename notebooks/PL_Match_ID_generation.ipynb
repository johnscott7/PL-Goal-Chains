{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d639455d-bd6e-478c-a913-f1b9e41c2a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 28778 — Liverpool v Bournemouth (2025-08-15 19:00)\n",
      "Fixture: ID 28778 — Liverpool v Bournemouth (2025-08-15 19:00)\n",
      "✔ shotsData found using this ID (great!)\n",
      "Pulled 29 shot events; showing first 5:\n",
      "  side  team            player minute                    xG       result\n",
      "0    a  None  Marcus Tavernier     34   0.35100075602531433    SavedShot\n",
      "1    a  None      David Brooks     41  0.038630276918411255  BlockedShot\n",
      "2    a  None  Marcus Tavernier     46  0.045542508363723755  BlockedShot\n",
      "3    a  None         Evanilson     48   0.09731415659189224  MissedShots\n",
      "4    a  None   Antoine Semenyo      5    0.3169209659099579  MissedShots\n",
      "Found 1 matches in window.\n",
      "→ ID 28778 — Liverpool v Bournemouth (2025-08-15 19:00)\n",
      "   ✓ 29 shots\n",
      "   ↳ saved C:\\Users\\jseat\\projects\\LiverpoolFC\\notebooks\\data\\raw\\Liverpool_v_Bournemouth_2025-08-15_shots.csv\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# NOTE (read me):\n",
    "# This script prints every EPL match ID (with the fixture text)\n",
    "# that falls within a given date window of the 2025/26 season,\n",
    "# and then attempts to pull shot events.\n",
    "#\n",
    "# ✅ What you edit:\n",
    "#   - Change START_DATE and END_DATE below (YYYY-MM-DD).\n",
    "#   - Optionally change LEAGUE and SEASON if you want a different league/season.\n",
    "#\n",
    "# ▶ How it works (briefly):\n",
    "#   - Fetch weekly league pages, decode `datesData = JSON.parse('...')`,\n",
    "#     collect fixtures, filter by your date window, de-duplicate by match_id,\n",
    "#     and print `ID <match_id> — <Home> v <Away> (<kickoff>)`.\n",
    "#   - For shots: attempts to read `shotsData` for each match page.\n",
    "#     (Future matches will naturally fail because shots don’t exist yet.)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import unicodedata\n",
    "from typing import Optional\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# ======== EDIT THESE ========\n",
    "LEAGUE = \"EPL\"\n",
    "SEASON = 2025\n",
    "START_DATE = \"2025-08-15\"\n",
    "END_DATE   = \"2025-08-15\"\n",
    "\n",
    "# Save per-match shots CSVs\n",
    "SAVE_CSV = True\n",
    "OUT_DIR = r\"C:\\Users\\jseat\\projects\\LiverpoolFC\\notebooks\\data\\raw\"\n",
    "# ============================\n",
    "\n",
    "BASE = \"https://understat.com\"\n",
    "S = requests.Session()\n",
    "S.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.google.com/\",\n",
    "})\n",
    "\n",
    "# ---------------------------\n",
    "# Generic helpers\n",
    "# ---------------------------\n",
    "\n",
    "def _fname_for_match(home: str, away: str, ko_ts) -> str:\n",
    "    \"\"\"Filesystem-safe, readable filename.\"\"\"\n",
    "    def slug(x: str) -> str:\n",
    "        # letters/numbers -> keep; everything else -> underscore; collapse repeats\n",
    "        return re.sub(r'[^A-Za-z0-9]+', '_', x).strip('_')\n",
    "    return f\"{slug(home)}_v_{slug(away)}_{ko_ts:%Y-%m-%d}_shots.csv\"\n",
    "\n",
    "def _decode_js_escaped(s: str) -> str:\n",
    "    \"\"\"Decode \\\\xNN / \\\\uXXXX style escapes from JSON.parse('...') payloads.\"\"\"\n",
    "    return bytes(s, \"utf-8\").decode(\"unicode_escape\")\n",
    "\n",
    "def _extract_array(text: str) -> str:\n",
    "    \"\"\"Quote/escape-aware bracket scan that returns the JSON array substring.\"\"\"\n",
    "    i = text.find(\"[\")\n",
    "    if i == -1:\n",
    "        raise RuntimeError(\"No '[' found in decoded datesData.\")\n",
    "    out, depth, esc, in_str, quote = [], 0, False, False, \"\"\n",
    "    j = i\n",
    "    while j < len(text):\n",
    "        ch = text[j]\n",
    "        out.append(ch)\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            elif ch == \"\\\\\":\n",
    "                esc = True\n",
    "            elif ch == quote:\n",
    "                in_str = False\n",
    "        else:\n",
    "            if ch in ('\"', \"'\"):\n",
    "                in_str = True; quote = ch\n",
    "            elif ch == \"[\":\n",
    "                depth += 1\n",
    "            elif ch == \"]\":\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    break\n",
    "        j += 1\n",
    "    if depth != 0:\n",
    "        raise RuntimeError(\"Unbalanced brackets while slicing datesData.\")\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _jsonparse_object(page_text: str, varname: str):\n",
    "    \"\"\"Extracts JSON.parse('...') object assigned to varname, returns Python object or None.\"\"\"\n",
    "    m = re.search(rf\"{re.escape(varname)}\\s*=\\s*JSON\\.parse\\('(.*?)'\\);\", page_text, flags=re.S)\n",
    "    if not m:\n",
    "        return None\n",
    "    decoded = _decode_js_escaped(m.group(1))\n",
    "    i = decoded.find(\"{\")\n",
    "    if i == -1:\n",
    "        return None\n",
    "    out, depth, in_str, esc, quote = [], 0, False, False, \"\"\n",
    "    for ch in decoded[i:]:\n",
    "        out.append(ch)\n",
    "        if in_str:\n",
    "            if esc: esc = False\n",
    "            elif ch == \"\\\\\": esc = True\n",
    "            elif ch == quote: in_str = False\n",
    "        else:\n",
    "            if ch in (\"'\", '\"'): in_str = True; quote = ch\n",
    "            elif ch == \"{\": depth += 1\n",
    "            elif ch == \"}\":\n",
    "                depth -= 1\n",
    "                if depth == 0: break\n",
    "    try:\n",
    "        return json.loads(\"\".join(out))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _jsonparse_array(page_text: str, varname: str):\n",
    "    \"\"\"Extracts JSON.parse('...') array assigned to varname, returns Python list or None.\"\"\"\n",
    "    m = re.search(rf\"{re.escape(varname)}\\s*=\\s*JSON\\.parse\\('(.*?)'\\);\", page_text, flags=re.S)\n",
    "    if not m:\n",
    "        return None\n",
    "    decoded = _decode_js_escaped(m.group(1))\n",
    "    i = decoded.find(\"[\")\n",
    "    if i == -1:\n",
    "        return None\n",
    "    out, depth, in_str, esc, quote = [], 0, False, False, \"\"\n",
    "    for ch in decoded[i:]:\n",
    "        out.append(ch)\n",
    "        if in_str:\n",
    "            if esc: esc = False\n",
    "            elif ch == \"\\\\\": esc = True\n",
    "            elif ch == quote: in_str = False\n",
    "        else:\n",
    "            if ch in (\"'\", '\"'): in_str = True; quote = ch\n",
    "            elif ch == \"[\": depth += 1\n",
    "            elif ch == \"]\":\n",
    "                depth -= 1\n",
    "                if depth == 0: break\n",
    "    try:\n",
    "        return json.loads(\"\".join(out))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _norm(s: Optional[str]) -> str:\n",
    "    \"\"\"ASCII-fold, drop diacritics, keep alnum/space, collapse whitespace, lowercase.\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = \"\".join(ch if ch.isalnum() or ch.isspace() else \" \" for ch in s)\n",
    "    return \" \".join(s.lower().split())\n",
    "\n",
    "def _slug(name: str) -> str:\n",
    "    \"\"\"Best-effort slug for team-season URL.\"\"\"\n",
    "    special = {\n",
    "        \"brighton\": \"Brighton\",\n",
    "        \"west_ham\": \"West_Ham\",\n",
    "        \"nottingham_forest\": \"Nottingham_Forest\",\n",
    "        \"crystal_palace\": \"Crystal_Palace\",\n",
    "        \"manchester_city\": \"Manchester_City\",\n",
    "        \"manchester_united\": \"Manchester_United\",\n",
    "        \"aston_villa\": \"Aston_Villa\",\n",
    "        \"newcastle_united\": \"Newcastle_United\",\n",
    "        \"wolverhampton_wanderers\": \"Wolverhampton_Wanderers\",\n",
    "        \"leeds_united\": \"Leeds_United\",\n",
    "    }\n",
    "    key = _norm(name).replace(\" \", \"_\")\n",
    "    return special.get(key, key.title().replace(\"_\", \"_\"))\n",
    "\n",
    "# ---------------------------\n",
    "# Fixtures (league week pages)\n",
    "# ---------------------------\n",
    "\n",
    "def _fetch_week_fixtures(league: str, season: int, week: int) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame of fixtures for a given week (or empty DF if none).\"\"\"\n",
    "    url = f\"{BASE}/league/{league}/{season}?week={week}\"\n",
    "    html = S.get(url, timeout=30)\n",
    "    html.raise_for_status()\n",
    "    text = html.text\n",
    "\n",
    "    # A) datesData = JSON.parse(' ... ');\n",
    "    m = re.search(r\"datesData\\s*=\\s*JSON\\.parse\\('(.*?)'\\);\", text, flags=re.S)\n",
    "    if m:\n",
    "        decoded = _decode_js_escaped(m.group(1))\n",
    "        arr_txt = _extract_array(decoded)\n",
    "        data = json.loads(arr_txt)\n",
    "    else:\n",
    "        # B) Fallback: datesData = [ ... ];\n",
    "        m2 = re.search(r\"datesData\\s*=\\s*(\\[[\\s\\S]*?\\]);\", text, flags=re.S)\n",
    "        if not m2:\n",
    "            return pd.DataFrame()  # week page without fixtures\n",
    "        data = json.loads(m2.group(1))\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # kickoff datetime (make tz-naive)\n",
    "    for col in (\"datetime\", \"date\", \"time\"):\n",
    "        if col in df.columns:\n",
    "            df[\"kickoff\"] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            break\n",
    "    else:\n",
    "        df[\"kickoff\"] = pd.NaT\n",
    "    df[\"kickoff\"] = df[\"kickoff\"].dt.tz_localize(None)\n",
    "\n",
    "    # Normalize a few common fields\n",
    "    if \"id\" in df.columns:\n",
    "        df[\"match_id\"] = df[\"id\"].astype(\"Int64\")\n",
    "    if \"h.title\" in df.columns:\n",
    "        df.rename(columns={\"h.title\": \"home_team\", \"a.title\": \"away_team\"}, inplace=True)\n",
    "\n",
    "    return df[[\"match_id\", \"home_team\", \"away_team\", \"kickoff\"]].copy()\n",
    "\n",
    "def _collect_fixtures_in_window(league: str, season: int, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Scan weeks until safely past the end of the window; return filtered+deduped DF.\"\"\"\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end_exclusive = pd.to_datetime(end_date) + pd.Timedelta(days=1)  # inclusive end\n",
    "    all_rows = []\n",
    "\n",
    "    # August usually spans weeks 1–3; keep a small safe range.\n",
    "    for week in range(1, 6):\n",
    "        df = _fetch_week_fixtures(league, season, week)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        all_rows.append(df)\n",
    "        # Early stop if clearly beyond the window\n",
    "        wk_min = df[\"kickoff\"].min()\n",
    "        if pd.notna(wk_min) and wk_min > end_exclusive + pd.Timedelta(days=7):\n",
    "            break\n",
    "\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame(columns=[\"match_id\", \"home_team\", \"away_team\", \"kickoff\"])\n",
    "\n",
    "    fixtures = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    # Filter to window\n",
    "    in_window = fixtures[(fixtures[\"kickoff\"] >= start) & (fixtures[\"kickoff\"] < end_exclusive)]\n",
    "\n",
    "    # De-duplicate by match_id\n",
    "    in_window = in_window.drop_duplicates(subset=[\"match_id\"]).sort_values(\"kickoff\").reset_index(drop=True)\n",
    "    return in_window\n",
    "\n",
    "# ---------------------------\n",
    "# Shots (match pages)\n",
    "# ---------------------------\n",
    "\n",
    "def _fetch_shots_by_match_id(match_id: int):\n",
    "    \"\"\"Fetch raw shotsData object (dict with 'h' and 'a') for a single match_id; None if missing.\"\"\"\n",
    "    url = f\"{BASE}/match/{match_id}\"\n",
    "    text = S.get(url, timeout=30).text\n",
    "\n",
    "    shots = _jsonparse_object(text, \"shotsData\")\n",
    "    if shots is None:\n",
    "        # fallback: plain object assignment\n",
    "        m2 = re.search(r\"shotsData\\s*=\\s*({[\\s\\S]*?});\", text, flags=re.S)\n",
    "        if m2:\n",
    "            try:\n",
    "                shots = json.loads(m2.group(1))\n",
    "            except Exception:\n",
    "                shots = None\n",
    "    return shots\n",
    "\n",
    "def fetch_shots_df(match_id: int) -> pd.DataFrame:\n",
    "    \"\"\"Return a tidy DataFrame of all shot events for a match_id (raises if not found).\"\"\"\n",
    "    shots = _fetch_shots_by_match_id(match_id)\n",
    "    if shots is None:\n",
    "        raise RuntimeError(f\"shotsData not found for match {match_id}\")\n",
    "\n",
    "    rows = []\n",
    "    for side in (\"h\", \"a\"):\n",
    "        for ev in shots.get(side, []):\n",
    "            rows.append({\n",
    "                \"match_id\": match_id,\n",
    "                \"side\": side,\n",
    "                \"team\": ev.get(\"team\"),\n",
    "                \"player\": ev.get(\"player\"),\n",
    "                \"player_id\": ev.get(\"player_id\"),\n",
    "                \"minute\": ev.get(\"minute\"),\n",
    "                \"second\": ev.get(\"second\"),\n",
    "                \"xG\": ev.get(\"xG\"),\n",
    "                \"result\": ev.get(\"result\"),\n",
    "                \"situation\": ev.get(\"situation\"),\n",
    "                \"shotType\": ev.get(\"shotType\"),\n",
    "                \"X\": ev.get(\"X\"),\n",
    "                \"Y\": ev.get(\"Y\"),\n",
    "                \"assist\": ev.get(\"assist\"),\n",
    "                \"assist_id\": ev.get(\"assist_id\"),\n",
    "                \"lastAction\": ev.get(\"lastAction\"),\n",
    "            })\n",
    "    return pd.DataFrame(rows).sort_values([\"side\", \"minute\", \"second\"], na_position=\"last\").reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Optional helper used by the demo to resolve a \"true\" match id\n",
    "# from team pages (kept as in your original code).\n",
    "# ---------------------------\n",
    "\n",
    "def _resolve_true_match_id_from_team(home: str, away: str, ko, season: int) -> Optional[int]:\n",
    "    for team in (home, away):\n",
    "        slug = _slug(team)\n",
    "        url = f\"{BASE}/team/{slug}/{season}\"\n",
    "        text = S.get(url, timeout=30).text\n",
    "\n",
    "        for var in (\"matchesData\", \"matches\"):\n",
    "            arr = _jsonparse_array(text, var)\n",
    "            if not isinstance(arr, list):\n",
    "                continue\n",
    "            target = {_norm(home), _norm(away)}\n",
    "            best, best_dt = None, pd.Timedelta(days=365)\n",
    "            for row in arr:\n",
    "                if not isinstance(row, dict):\n",
    "                    continue\n",
    "                h = (row.get(\"h\", {}) or {}).get(\"title\") or row.get(\"h.title\")\n",
    "                a = (row.get(\"a\", {}) or {}).get(\"title\") or row.get(\"a.title\")\n",
    "                if not h or not a:\n",
    "                    continue\n",
    "                if {_norm(h), _norm(a)} != target:\n",
    "                    continue\n",
    "                dt = row.get(\"datetime\") or (f\"{row.get('date','')} {row.get('time','')}\".strip() or None)\n",
    "                t = pd.to_datetime(dt, errors=\"coerce\")\n",
    "                if pd.isna(t):\n",
    "                    continue\n",
    "                t = t.tz_localize(None)\n",
    "                diff = abs(t - ko)\n",
    "                if diff < best_dt:\n",
    "                    best_dt, best = diff, row.get(\"id\")\n",
    "            if best:\n",
    "                return int(best)\n",
    "    return None\n",
    "\n",
    "# ---------------------------\n",
    "# Runners\n",
    "# ---------------------------\n",
    "\n",
    "def print_fixtures_in_window():\n",
    "    \"\"\"Print fixtures and IDs within the date window.\"\"\"\n",
    "    win = _collect_fixtures_in_window(LEAGUE, SEASON, START_DATE, END_DATE)\n",
    "    if win.empty:\n",
    "        print(f\"No fixtures found between {START_DATE} and {END_DATE}.\")\n",
    "        return\n",
    "    for _, r in win.iterrows():\n",
    "        mid  = int(r[\"match_id\"])\n",
    "        home = r.get(\"home_team\", \"\")\n",
    "        away = r.get(\"away_team\", \"\")\n",
    "        ko   = r[\"kickoff\"].strftime(\"%Y-%m-%d %H:%M\")\n",
    "        print(f\"ID {mid} — {home} v {away} ({ko})\")\n",
    "\n",
    "def demo_one():\n",
    "    \"\"\"Minimal demo on the first match in window (unchanged behavior).\"\"\"\n",
    "    win = _collect_fixtures_in_window(LEAGUE, SEASON, START_DATE, END_DATE)\n",
    "    if win.empty:\n",
    "        print(\"No fixtures in window.\")\n",
    "        return\n",
    "    r = win.iloc[0]\n",
    "    mid, home, away, ko = int(r[\"match_id\"]), r[\"home_team\"], r[\"away_team\"], r[\"kickoff\"]\n",
    "    print(f\"Fixture: ID {mid} — {home} v {away} ({ko:%Y-%m-%d %H:%M})\")\n",
    "\n",
    "    # 1) Try using the small ID directly\n",
    "    shots = _fetch_shots_by_match_id(mid)\n",
    "    if shots:\n",
    "        print(\"✔ shotsData found using this ID (great!)\")\n",
    "    else:\n",
    "        print(\"✖ shotsData NOT found with this ID; resolving true Understat match id…\")\n",
    "        true_id = _resolve_true_match_id_from_team(home, away, ko, SEASON)\n",
    "        if not true_id:\n",
    "            print(\"Could not resolve a true Understat match id from team pages.\")\n",
    "            return\n",
    "        print(f\"Resolved true match id: {true_id}\")\n",
    "        shots = _fetch_shots_by_match_id(true_id)\n",
    "        if not shots:\n",
    "            print(\"Even the true id returned no shotsData; page structure may have changed.\")\n",
    "            return\n",
    "\n",
    "    # Print a few events\n",
    "    rows = []\n",
    "    for side in (\"h\", \"a\"):\n",
    "        for ev in shots.get(side, []):\n",
    "            rows.append({\n",
    "                \"side\": side,\n",
    "                \"team\": ev.get(\"team\"),\n",
    "                \"player\": ev.get(\"player\"),\n",
    "                \"minute\": ev.get(\"minute\"),\n",
    "                \"xG\": ev.get(\"xG\"),\n",
    "                \"result\": ev.get(\"result\"),\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"side\", \"minute\"]).reset_index(drop=True)\n",
    "    print(f\"Pulled {len(df)} shot events; showing first 5:\")\n",
    "    print(df.head(5))\n",
    "\n",
    "def fetch_all_matches_in_window():\n",
    "    \"\"\"Iterate all matches in the window and attempt to fetch shot events.\"\"\"\n",
    "    win = _collect_fixtures_in_window(LEAGUE, SEASON, START_DATE, END_DATE)\n",
    "    if win.empty:\n",
    "        print(f\"No fixtures found between {START_DATE} and {END_DATE}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(win)} matches in window.\")\n",
    "    for _, r in win.iterrows():\n",
    "        mid  = int(r[\"match_id\"])\n",
    "        home = r.get(\"home_team\", \"\")\n",
    "        away = r.get(\"away_team\", \"\")\n",
    "        ko   = r[\"kickoff\"].strftime(\"%Y-%m-%d %H:%M\")\n",
    "        print(f\"→ ID {mid} — {home} v {away} ({ko})\")\n",
    "\n",
    "        try:\n",
    "            df = fetch_shots_df(mid)\n",
    "        except Exception as e:\n",
    "            print(f\"   △ failed to fetch shots: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"   ✓ {len(df)} shots\")\n",
    "        if SAVE_CSV:\n",
    "            os.makedirs(OUT_DIR, exist_ok=True)\n",
    "            out_name = _fname_for_match(home, away, r[\"kickoff\"])\n",
    "            out_path = os.path.join(OUT_DIR, out_name)\n",
    "            df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"   ↳ saved {out_path}\")\n",
    "\n",
    "        time.sleep(0.6)  # be polite\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Print fixture IDs in window\n",
    "    print_fixtures_in_window()\n",
    "\n",
    "    # 2) Minimal one-match demo (as in your original code)\n",
    "    demo_one()\n",
    "\n",
    "    # 3) Attempt shots for all matches in the window\n",
    "    fetch_all_matches_in_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b559e-91f4-447d-a016-f1fa8cf6518b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pl311]",
   "language": "python",
   "name": "conda-env-pl311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
